# 命令&数据

## 文件上传
```
obsutil cp .h5 obs://yml-hw201908/weights/
obsutil cp obs://yml-hw201908/garbage_classify/new_img.zip .
```
## 登录服务器
```
ssh -oPort=6022 yangjin@139.159.233.164
```
## 进入docker
```
docker exec -it tf-gpu bash
```
## 评审账号 ID
d8126a20db13499c82e060007d1e8348

## TODO
[x]目标检测
[ ]对比度归一化
[x]直方图均衡化
[x]数据扩充到1000张
[x]图像变为299 * 299
[x]细分类
[x]全连接层改成64
[x]batch normalization
[ ]MaxOut
[x]Noise
[x]多模型投票
[ ]随机通道翻转
[x]channel_shift_range
[x]截取部分模型
[x]relu -> sigmoid
[x]加一层全连接
[x]锁层102
[ ]修改模型
[x]InceptionResnetV2+LGBM
[x]EfficientNet换preprocess torch -> tf
[x]32倍测试集扩充
[x]多GPU
[x]ReduceLROnPlateau
[x]B7锁层训练
[x]动态数据增强
[ ]修改初始化器
[x]Dropout
[x]Batch Noramlization
[x]ReduceLROnPlateau val_acc 0.5 3
[x]B4
[x]tanh 
[x]去掉relu
[x]B5锁层临界点
[x]提高部分类权重 
[x]正则化
[x]锁更多层
[x]双网络
[x]dropout 0.4, 0.6

```
[True, False, False, False, False, False, False, False,  True,
 True, False, False, False, False,  True,  True,  True, False,
 False, False, False, False,  True,  True, False, False, False,
 False, False, False, False,  True,  True,  True, False, False,
 True, False, False, False]
```
[x]验证集不shuffle，删除部分验证集图片
[x]Label Smooth
 
# ChangeLog

## 9.6
### EfficientNet-B5-9.5.14-2 => EfficientNet-B5-9.6.9-23
扩充数据，batch_size=32
### EfficientNet-B5-9.6.9-23 => EfficientNet-B5-9.6.10-01
移除全连接




### EfficientNet-B5-9.5.14-2 => EfficientNet-B5-9.6.1-0

### EfficientNet-B5-9.6.1-0 => EfficientNet-B5-9.6.2-1

### EfficientNet-B5-9.5.14-2 => EfficientNet-B7-9.6.3-2
Efficient-B7 => 太慢
### EfficientNet-B5-9.5.14-2 => EfficientNet-B5-9.6.4-3
两层全连接 => 0.94192 | 加relu => 0.93852
### EfficientNet-B5-9.5.14-2 => EfficientNet-B5-9.6.5-0
加一层dropout => 0.94260
### EfficientNet-B5-9.5.14-2 => EfficientNet-B5-9.6.6-1
0.93920 | 加残差：0.94327
```
x = base_model.output

x = SeparableConv2D(2048, (3, 3),
                   padding='same',
                   use_bias=False)(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)

x = GlobalAveragePooling2D()(x)
x=Dropout(0.5)(x)
```
### EfficientNet-B5-9.5.14-2 => EfficientNet-B5-9.6.7-2
0.93105 | 2048//16 : 0.93784
```
x = base_model.output

squeeze = GlobalAveragePooling2D()(x)
excitation = Dense(units=2048 // 40)(squeeze)
excitation = Activation('relu')(excitation)
excitation = Dense(units=2048)(excitation)
excitation = Activation('sigmoid')(excitation)
excitation = Reshape((1, 1, 2048))(excitation)

scale = multiply([x, excitation])

x = GlobalAveragePooling2D()(scale)
x=Dropout(0.5)(x)
```
### EfficientNet-B5-9.6.8-0
0.94463


## 9.5
### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.5.1-0
dropout 0.4 => 0.94019
### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.5.2-1
dropout 0.6 => 0.94052
### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.5.3-2
随机放大 => 0.92675
### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.5.4-3
增大图像尺寸528 * 528 => 0.94388
### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.5.5-0
2/3 => 0.93716
### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.5.6-1
1/6
### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.5.7-2
锁250层 => 0.9422
### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.5.8-3
加入残差块 => 0.94052
### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.5.9-0 @@@@@@@@@@@重新跑
patience = 2

### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.5.10-1 @@@@@@@@@@@重新跑
patience = 1

### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.5.11-
```
x = SeparableConv2D(2048, (3, 3),
               padding='same',
               use_bias=False)(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
```

### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.5.12-0
修改数据集 => 0.94293
### EfficientNet-B5-9.5.12-0 => EfficientNet-B5-9.5.13-1
patience=2 => 0.94531
### EfficientNet-B5-9.5.12-0 => EfficientNet-B5-9.5.14-2
patience=1 => 0.94769, Score = 0.945124
### EfficientNet-B5-9.5.12-0 => EfficientNet-B5-9.5.15-3
label smoothing => 0.940




## 9.4
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.4.1-0
dense前加dropout => 0.94321
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.4.2-1
dense前加dropout，删除dense后dropout => 0.94254
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.4.3-2
l2 = 0.01
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.4.4-3
l2 = 0.1 => 0.94321
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.4.5-2
每类只保留280样本 => 0.93246
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.4.6-0 @@@@@@@@重新跑
30epoch, val_acc = 0.94724, Score = 0.944467 ！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！
```
ig = ImageDataGenerator(preprocessing_function=efn.preprocess_input,
                horizontal_flip=True,
                vertical_flip=True)
```
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.4.7-1
dropout0.8  => 0.93750
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.4.8-2
使用两个网络 => 0.94355
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.4.9-3
不同尺寸共享权重
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.4.10-3
调换BN与Dropout顺序
### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.4.11-0
去掉垂直翻转 => 0.94321
### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.4.12-1
0.94456
```
DENSE_KERNEL_INITIALIZER = {
    'class_name': 'VarianceScaling',
    'config': {
        'scale': 1.,
        'mode': 'fan_out',
        'distribution': 'uniform'
    }
}
```
### EfficientNet-B5-9.4.8-2 => EfficientNet-B5-9.4.13-2
0.94321
```
x = Concatenate()([base_model_a.output,base_model_b.output])
```
### EfficientNet-B5-9.4.6-0 => EfficientNet-B5-9.4.14-3
0.94019
```
x = base_model.output

x = Conv2D(1024,(3,3),activation='relu',padding='valid')(x)
x = GlobalAveragePooling2D()(x)

x = Dense(128)(x)
x = BatchNormalization()(x)
x=Dropout(0.5)(x)
```




## 9.3
### EfficientNet-B5-9.2.11-3 => EfficientNet-B5-9.3.1-0
锁200层 => 0.92809
### EfficientNet-B5-9.2.11-3 => EfficientNet-B5-9.3.2-2
锁200层，删除BN => 0.93349
### baseline-EfficientNet-B5 => EfficientNet-B5-9.3.3-1
preprocess_v8，不均衡数据 => 0.94362 Score = 0.936765
### EfficientNet-B5-9.3.3-1 => EfficientNet-B5-9.3.4-3
设置class_weights => 0.94362 
### EfficientNet-B5-9.3.3-1 => EfficientNet-B5-9.3.5-0
数据增强 => 0.9318
### EfficientNet-B5-9.3.3-1 => EfficientNet-B5-9.3.6-2
锁200层 => 0.94261

### EfficientNet-B5-9.3.4-3 => EfficientNet-B5-9.3.7-1
0.94429
```
x = Dense(128)(x)
x = BatchNormalization()(x)
x=Dropout(0.3)(x)
```
### EfficientNet-B5-9.3.4-3 => EfficientNet-B5-9.3.8-3
0.94733
```
x = Dense(128)(x)
x = BatchNormalization()(x)
x=Dropout(0.5)(x)
```
### EfficientNet-B5-9.3.4-3 => EfficientNet-B5-9.3.9
0.9368
```
x = Dense(128)(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x=Dropout(0.3)(x)
```
### EfficientNet-B5-9.3.4-3 => EfficientNet-B5-9.3.10
```
x = Dense(128)(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x=Dropout(0.5)(x)
```
### EfficientNet-B5-9.3.8-3 => EfficientNet-B5-9.3.11-0
0.94556 ,Score = 0.940008！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！
```
valid_g = ig.flow_from_dataframe(labels_valid[:-(labels_valid.shape[0] % batch_size)], path_data_valid, shuffle=False, **params_g)
```
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.3.12-1
修改部分类权重 => 0.94422
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.3.13-2
去掉BN => 0.94187
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.3.14-3
去掉GlobalAveragePooling => 0.92876
```
x = Flatten()(x)
x = Dense(128)(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
```
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.3.15
去掉GlobalAveragePooling
```
x = Flatten()(x)
x = Dense(128)(x)
x = BatchNormalization()(x)
x=Dropout(0.5)(x)
```
### EfficientNet-B5-9.3.11-0 => EfficientNet-B5-9.3.16
去掉GlobalAveragePooling
```
x = Flatten()(x)
x = Dense(128,activation='relu')(x)
x=Dropout(0.5)(x)
```


## 9.2 
### EfficientNet-B5-9.1.9-1 => EfficientNet-B5-9.2.1-0
dropout 0.5 => 0.93585
### EfficientNet-B5-9.1.9-1 => EfficientNet-B5-9.2.2-2
dense(512) => 0.93383
### EfficientNet-B5-9.1.9-1 => EfficientNet-B5-9.2.3-3
dropout 0.5 , dense(512) => 0.93113
### EfficientNet-B5-9.1.9-1 => EfficientNet-B5-9.2.4-1
删除BatchNormalization => 0.93383
### EfficientNet-B5-9.1.9-1 => EfficientNet-B5-9.2.5-0
0.93214
```
reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5,patience=3, min_lr=1e-5,verbose=1)
```
### EfficientNet-B5-9.1.9-1 => EfficientNet-B5-9.2.6-1
0.93113
```
x = BatchNormalization()(x)
x = Dense(128)(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x=Dropout(0.3)(x)
```
### EfficientNet-B5-9.1.9-1 => EfficientNet-B5-9.2.7-2
0.93678
```
predictions = Dense(n_classess, activation='softmax')(x)
```
### EfficientNet-B5-9.1.9-1 => EfficientNet-B5-9.2.8-3
0.93113
```
x = Dense(128,kernel_regularizer=keras.regularizers.l2(0.1))(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x=Dropout(0.3)(x)
```
### baseline-EfficientNet-B4
baseline-EfficientNet-B4 => 0.92775
### EfficientNet-B5-9.1.9-1 => EfficientNet-B5-9.2.9-1
锁层200 => 0.93687
### EfficientNet-B5-9.1.9-1 => EfficientNet-B5-9.2.10-2
tanh => 0.93889
### EfficientNet-B5-9.1.9-1 => EfficientNet-B5-9.2.11-3
删除relu => 0.94058 ！！！！！！！！！！！！！！！！！！！！！


## 9.1
### baseline-EfficientNet-B5 => EfficientNet-B5-9.1.1-2
锁层 10 => 0.89705
### baseline-EfficientNet-B5 => EfficientNet-B5-9.1.2-3
锁层 100 => 0.9296
### baseline-EfficientNet-B5 => EfficientNet-B5-9.1.3-1
锁层 285 => 0.9345
### baseline-EfficientNet-B5 => EfficientNet-B5-9.1.4-0
ReduceLROnPlateau => 0.93367
### baseline-EfficientNet-B5 => EfficientNet-B7-9.1.1-2
B7，锁250层 => 0.92741
### EfficientNet-B5-9.1.3-1 => EfficientNet-B5-9.1.5-3
随机缩放 => 0.8964
###  EfficientNet-B5-9.1.3-1 =>  EfficientNet-B5-9.1.6
加入全连接层和dropout 0.3 => 0.929439
###  EfficientNet-B5-9.1.3-1 =>  EfficientNet-B5-9.1.7
加入Batch Noramlization => 0.92606
###  EfficientNet-B5-9.1.3-1 => EfficientNet-B5-9.1.8-3
droput 0.3 => 0.93585
###  EfficientNet-B5-9.1.3-1 => EfficientNet-B5-9.1.9-1
0.93788 ！！！！！！！！！！！！！！！！！
```
x = Dense(128)(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x=Dropout(0.3)(x)
```

## 8.31
### baseline-EfficientNet-B5 => EfficientNet-B5-8.31.1-1
修改预处理 => 0.9316

## 8.30
### baseline-InceptionResNetV2-Xception
修复bug重跑 => 0.8812
### baseline-InceptionResNetV2-Xception => InceptionResNetV2-Xception-8.30.1-2
全连接改为256 => 0.8937
### baseline-InceptionResNetV2-Xception => InceptionResNetV2-Xception-8.30.2-1
取消全连接 => 0.9139
### baseline-InceptionResNetV2-Xception => InceptionResNetV2-Xception-8.30.3-0
include_top = True
### baseline-BCNN-InceptionResNetV2
Bilinear CNN + InceptionResnet => 0.8791
### baseline-EfficientNet-B7
baseline-EfficientNet-B7 => 0.9253
### baseline-EfficientNet-B6
baseline-EfficientNet-B6 => 0.9263
### baseline-EfficientNet-B5
baseline-EfficientNet-B5
！！！！！！！！！！！！！！！！！！！！！！！！
va_acc = 0.93434
1 * TTA:0.932509
8 * TTA:0.93332
16 * TTA:0.931496
32 * TTA:0.930888



### baseline-EfficientNet-B5=> EfficientNet-B5-8.31.2-23
双显卡；lr=1e-4 => 0.92269


## 8.29
### baseline-InceptionResNetV2=>InceptionResNetV2-8.29.1-0
锁层，mixed_5b => val_acc = 0.8934
### baseline-InceptionResNetV2=>InceptionResNetV2-8.29.2-1
锁层，mixed_6a => val_acc = 0.8890
### baseline-InceptionResNetV2=>InceptionResNetV2-8.29.3-2
锁层，mixed_7a => val_acc = 0.8907
### baseline-InceptionResNetV2=>InceptionResNetV2-8.29.4-3
加一层全连接 => val_acc = 0.9056
### InceptionResNetV2-8.29.4-3=>InceptionResNetV2-8.29.5-3
加一层Dropout
### baseline-Xception=>Xception-8.29.1-0
不加载预训练权重 => 中止
### baseline-Xception=>Xception-8.29.2-1
原版Xception，不额外添加层
### Xception-8.29.2-1=>Xception-8.29.3-2
中间8个block -> 6个block
### baseline-InceptionResNetV2-Xception=>InceptionResNetV2-Xception-8.29.1-0
Bilinear CNN => 跑不动
### baseline-InceptionResNetV2 => InceptionResNetV2-LGBM-8.29.1-0
InceptionResNetV2 + LGBM

## 8.28
### baseline-InceptionResNetV2=>InceptionResNetV2-8.28.1-1
relu -> sigmoid => val_acc = 0.90020
### baseline-InceptionResNetV2=>InceptionResNetV2-8.28.2-2
去掉relu => val_acc = 0.90801

### 重跑baseline 
preprocess_v7，增加数据集
### baseline-Xception
Xception => val_acc = 0.9093, Score = 0.89542

### baseline-NASNetLarge
NASNetLarge => val_acc = 0.91549,Score = 

### baseline-ResNeXt50
ResNeXt50 => val_acc = 0.90311, Score = 0.895622

### baseline-InceptionResNetV2
InceptionResNetV2 => val_acc = 0.9097, Score = 

## 8.27
### InceptionResNetV2-Xception-8.27.1-1=> InceptionResNetV2-Xception-8.27.4-3
dropout=0.5 => val_acc = 0.88251

### InceptionResNetV2-8.26.5-3 => InceptionResNetV2-8.27.1-0
dropout=0.5 => val_acc = 0.89579

### baseline-InceptionResNetV2 => InceptionResNetV2-8.27.2-1
截取InceptionResNetV2的一部分 mixed_6a => 效果很差
### baseline-InceptionResNetV2 => InceptionResNetV2-8.27.3-2
截取InceptionResNetV2的一部分 mixed_7a => 效果很差
### baseline-InceptionResNetV2 => InceptionResNetV2-8.27.4-1
效果不好
```
# x = GlobalAveragePooling2D()(x)
x = Conv2D(256,(5,5),activation='relu')(x)
x = Flatten()(x)
```
### baseline-InceptionResNetV2 => baseline-InceptionResNetV2-Xception
模型融合
### baseline-InceptionResNetV2-Xception => InceptionResNetV2-Xception-8.27.1-1



## 8.26
### baseline-InceptionResNetV2=>InceptionResNetV2-8.26.*


### baseline-InceptionResNetV2=>InceptionResNetV2-8.26.4-3
channel_shift_range=30

### InceptionResNetV2-8.26.4-3 => InceptionResNetV2-8.26.5-3
```
ig = ImageDataGenerator(preprocessing_function=preprocess_img,
                channel_shift_range=30,
                width_shift_range=50,
                height_shift_range=50,
                shear_range=30,
                zoom_range=0.4)
```

## 8.25
多模型融合
### baseline-InceptionResNetV2=>InceptionResNetV2-8.25.3-2
dropout=0.5 val_acc=0.91242
maxpooling效果不如averagePooling
dropout=0.3效果不如0.5


## 8.24
preprocess_v6，重跑baseline
### baseline-Xception
Xception => val_acc = 0.90971, Score = 0.89623

### baseline-NASNetLarge
NASNetLarge => val_acc = 0.9202,Score = 0.911634

### baseline-ResNeXt50
ResNeXt50 => val_acc = 0.9028, Score = 0.894609

### baseline-InceptionResNetV2
InceptionResNetV2 => val_acc = 0.9060, Score = 0.897852

## 8.23
图片裁剪成正方形，重跑baseline
### baseline-Xception
16 min/epoch, batch_size = 32, img_size = 299
Xception => val_acc = 0.8999， Score = 0.887515

### baseline-NASNetLarge
75 min/epoch, batch_size = 8, img_size = 331
NASNetLarge => val_acc = 0.9108， Score = 0.90758

### baseline-ResNeXt50
24 min/epoch, batch_size = 16, img_size = 224
ResNeXt50 => val_acc = 0.8923， Score = 0.886502

### baseline-InceptionResNetV2
15 min/epoch, batch_size = 32, img_size = 299
InceptionResNetV2 => val_acc = 0.9084， Score = 0.899068


## 8.22
### baseline-NASNetLarge => NASNetLarge-8.22.1-0
原始331 * 331 => val_acc = 0.9222, Score = 0.913052
### baseline-NASNetLarge => NASNetLarge-8.22.2-1
学习率调为1e-4 => 很差
### baseline-NASNetLarge => NASNetLarge-8.22.3-2
删除全连接 => val_acc = 0.9178, Score = 0.911026
### baseline-NASNetLarge => NASNetLarge-8.22.4-3
删除全连接，学习率调为1e-4 => val_acc = 0.8431
### baseline-NASNetLarge => NASNetLarge-8.22.5-1
直方图均衡化 => 效果很差


## 8.21
### exp2.8.19.2 => Baseline
基准代码，1000样本，299 * 299， preprocess_v4
### baseline-Xception
Xception => val_acc = 0.89885， Score = 0.889339

### baseline-NASNetLarge
NASNetLarge => val_acc = 0.91717， Score = 0.909201

### baseline-ResNeXt50
ResNeXt50 => val_acc = 0.89568， Score = 

### baseline-InceptionResNetV2
InceptionResNetV2 => val_acc = 0.90699， Score = 


## 8.20
### bottles.0.8.20.1 bottles.2.8.20.1 bottles.3.8.20.1
对瓶子细分类 => 效果很差

## 8.19
### exp3.8.18.2 => exp1.8.19.1
droput=0.5 -> droput=0.6 => val_acc = 0.8897
### exp3.8.18.2 => exp2.8.19.1
x = Dense(128, activation='relu')(x) -> x = Dense(128)(x) => 0.8890
### exp3.8.18.2 => exp3.8.19.1
输入添加高斯噪声 => 超级慢
### exp3.8.18.2 => exp4.8.19.1
dropout转BatchNormalization  => val_acc=0.8897
```
x = Dense(128, activation='relu')(x)
x = BatchNormalization()(x)
```
### exp2.8.18.3 => exp2.8.19.2
224 -> 299 => val_acc = val_acc = 0.9117 , Score = 0.917106 ！！！！！！！！！！！！！
### exp3.8.17.1 => exp3.8.19.2
224 -> 299 => val_acc = 0.8859
### exp3.8.19.2 => exp1.8.19.2
dropout0.3 => val_acc = 0.8914
### exp3 => exp4.8.19.2
mobilenet_v2 => val_acc = 0.8432




## 8.18
### exp1.8.17.3 => exp1.8.18.1
lr = 1e-5 -> 1e-6 => val_acc = 0.8754，超级慢
### exp2.8.16.2 => exp2.8.18.1
迁移学习 block6~14 => val_acc = 0.8737，过拟合
### exp1.8.17.3 => exp3.8.18.1
val_acc = 0.8897,Score = 0.899676   ！！！！！！
```
x = Dense(128, activation='relu')(x)
x=Dropout(0.3)(x)
```
### exp1.8.17.3 => exp4.8.18.1
val_acc = 0.8863
```
x=Dropout(0.3)(x)
x = Dense(128, activation='relu')(x)
```

### exp1.8.17.3 => exp2.8.18.2
Dense(128, activation='relu') -> Dense(64, activation='relu')
Adam(lr=1e-5) -> Adam(lr=1e-4) => 0.8683，过拟合，验证集得分越来越低

### exp1.8.17.3 => exp1.8.18.2
preprocess_v4 => val_acc = 0.8921
### exp3.8.18.1 => exp2.8.18.3
preprocess_v4 => val_acc = 0.8927
### exp3.8.18.1 => exp3.8.18.2
preprocess_v4,droput=0.5 => val_acc = 0.8944 ,Score = 0.897446 ？？？？？？
### exp3.8.18.1 => exp4.8.18.2
preprocess_v4 => val_acc = 0.8876
```
x=Dropout(0.3)(x)
x = Dense(128, activation='relu')(x)
x=Dropout(0.3)(x)
```

## 8.17

### preprocess => prerocess_v3
BICUBIC -> LANCZOS, 每类固定6000样本

### exp1 => exp1.8.17.1
使用preprocess_v3的数据训练 => 0.8535

### exp2.8.16.2 => exp2.8.17.1
使用preprocess_v3的数据训练

### exp3 => exp3.8.17.1
使用preprocess_v3的数据训练 => val_acc = 0.874, Score=0.870 

### exp2.8.16.2 => exp4.8.17.1
使用preprocess_v3的数据训练, 迁移学习 block6~14 => val_acc = 0.824


### exp2 => exp2.8.17.2
NASNetMobile -> Resnet50 => val_acc = 0.81
### exp1 => exp1.8.17.2
InceptionResNetV2 -> ResNet101
### exp3.8.17.1 => exp3.8.17.2
删除最后的全连接层
### exp3.8.17.1 => exp2.8.17.3
lr = 1e-4 -> 1e-3

---------------------------------以上废了
### exp3.8.17.1 => exp1.8.17.3
lr = 1e-4 -> 1e-5 => val_acc = 0.8873, Score = 0.8988   ！！！！！
### exp3.8.17.1 => exp2.8.17.4
Adam(lr=1e-4) -> SGD(lr=0.0001, momentum=0.9) => 训练极慢
### exp3.8.17.1 => exp3.8.17.3
Dense(128, activation='relu') -> Dense(512, activation='relu') =>  0.8653 过拟合，验证集得分越来越低
### exp3.8.17.1 => exp4.8.17.2
修改全连接层 => 0.8737 过拟合，验证集得分越来越低
```
x = Dense(512, activation='relu')(x)
x=Dropout(0.5)(x)
x = Dense(128, activation='relu')(x)
```
### exp3.8.17.1 => exp2.8.17.5
修改全连接层 => 0.873 过拟合，验证集得分越来越低
```
x = Dense(512, activation='relu')(x)
x=Dropout(0.3)(x)
x = Dense(128, activation='relu')(x)
x=Dropout(0.3)(x)
```

## 8.16

### exp1 => exp1.8.16:
GlobalAveragePooling2D -> GlobalMaxPooling2D => val_acc = 0.834
GlobalMaxPooling2D -> Flatten => val_acc = 0.8305

### exp2 => exp2.8.16
NASNetMobile -> Xception, imagenet -> None => val_acc = 0.4


### exp3 => exp3.8.16
GlobalAveragePooling2D -> GlobalMaxPooling2D => val_acc = 0.843

### exp3 => exp3.8.16.2
Dense(128, activation='relu') -> Dense(1024, activation='relu') => val_acc = 0.8425

### exp3 => exp2.8.16.2
迁移学习 block10~14 => 0.8201

### exp3 => exp4.8.16
迁移学习 block13~14 => val_acc = 0.8096


## 8.15
exp1 - InceptionResNetV2 => val_acc = 0.8431
exp2 - NASNetMobile => val_acc = 0.80
exp3 - Xception => val_acc = 0.8481，Score=0.847183
exp4 - NASNetLarge => pass




